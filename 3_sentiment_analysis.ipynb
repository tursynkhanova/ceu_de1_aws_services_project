{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7dfc81f",
   "metadata": {},
   "source": [
    "### Step 3: Now that every article is in English, we can check their sentiments using Amazon Comprehend. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2bbb3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70713e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_REGION = 'eu-west-1'\n",
    "S3_BUCKET_NAME = 'aruzhan-sabira-hw3' \n",
    "\n",
    "# S3 prefixes containing ALL English-language articles\n",
    "S3_INPUT_PREFIXES = [\n",
    "    'raw_articles/english/', \n",
    "    'translated_articles/'\n",
    "]\n",
    "S3_OUTPUT_PREFIX = 'sentiment_results_sync/' # New folder for results of the service\n",
    "\n",
    "s3_client = boto3.client('s3', region_name=AWS_REGION)\n",
    "comprehend_client = boto3.client('comprehend', region_name=AWS_REGION)\n",
    "MAX_TEXT_BYTES = 4900 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26761c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text_content):\n",
    "    \"\"\"\n",
    "    Analyzes sentiment of the text using Comprehend's synchronous API.\n",
    "    Handles text chunking to stay within the 5000 byte limit.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Text must be encoded to bytes for accurate length check\n",
    "    original_bytes = text_content.encode('utf-8')\n",
    "    current_index = 0\n",
    "    total_bytes = len(original_bytes)\n",
    "    \n",
    "    # We will analyze sentiment for the first chunk only (simplification for time)\n",
    "    # For a deep analysis, you would average the sentiment of all chunks.\n",
    "    \n",
    "    if total_bytes == 0:\n",
    "        return {'Sentiment': 'NEUTRAL', 'SentimentScore': {'Mixed': 0, 'Positive': 0, 'Negative': 0, 'Neutral': 0}}\n",
    "        \n",
    "    end_index = min(current_index + MAX_TEXT_BYTES, total_bytes)\n",
    "    \n",
    "    # Safety check to avoid splitting a multi-byte character\n",
    "    while end_index < total_bytes and (original_bytes[end_index] & 0xC0) == 0x80:\n",
    "        end_index -= 1\n",
    "\n",
    "    byte_chunk = original_bytes[current_index:end_index]\n",
    "    \n",
    "    try:\n",
    "        string_chunk = byte_chunk.decode('utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        print(\"  [ERROR] Unicode decode error on chunk. Cannot analyze.\")\n",
    "        return {'Sentiment': 'ERROR', 'SentimentScore': {}}\n",
    "\n",
    "    try:\n",
    "        response = comprehend_client.detect_sentiment(\n",
    "            Text=string_chunk, \n",
    "            LanguageCode='en' \n",
    "        )\n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  [ERROR] Comprehend analysis failed on chunk. Error: {e}\")\n",
    "        return {'Sentiment': 'ERROR', 'SentimentScore': {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27e377c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_s3_file(bucket_name, input_key):\n",
    "    \"\"\"Downloads a file, analyzes sentiment, and uploads the result.\"\"\"\n",
    "    \n",
    "    print(f\"\\nProcessing file: {input_key}\")\n",
    "\n",
    "    # 1. Download file content from S3\n",
    "    try:\n",
    "        response = s3_client.get_object(Bucket=bucket_name, Key=input_key)\n",
    "        # Read the file content as a string\n",
    "        original_text = response['Body'].read().decode('utf-8')\n",
    "    except Exception as e:\n",
    "        print(f\"  [ERROR] Failed to read object {input_key}. Skipping. Error: {e}\")\n",
    "        return\n",
    "\n",
    "    # 2. Analyze Sentiment\n",
    "    sentiment_response = analyze_sentiment(original_text)\n",
    "    \n",
    "    # 3. Create Result Object\n",
    "    result_data = {\n",
    "        'SourceFile': input_key,\n",
    "        'Sentiment': sentiment_response['Sentiment'],\n",
    "        'ConfidenceScores': sentiment_response['SentimentScore'],\n",
    "        'LanguageCode': 'en',\n",
    "        'AnalysisTime': time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }\n",
    "\n",
    "    # 4. Upload result to S3\n",
    "    original_filename = os.path.basename(input_key)\n",
    "    output_key = S3_OUTPUT_PREFIX + original_filename.replace('.txt', '.json')\n",
    "    \n",
    "    try:\n",
    "        s3_client.put_object(\n",
    "            Bucket=bucket_name, \n",
    "            Key=output_key, \n",
    "            Body=json.dumps(result_data, indent=2).encode('utf-8'),\n",
    "            ContentType='application/json'\n",
    "        )\n",
    "        print(f\"  [SUCCESS] Sentiment analyzed: {result_data['Sentiment']}. Results uploaded to s3://{bucket_name}/{output_key}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  [ERROR] Failed to upload result object. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8d83e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting synchronous sentiment analysis in region eu-west-1...\n",
      "\n",
      "--- Listing files in raw_articles/english/ ---\n",
      "\n",
      "Processing file: raw_articles/english/ai-bubble-us-economy_1765755103.txt\n",
      "  [SUCCESS] Sentiment analyzed: NEUTRAL. Results uploaded to s3://aruzhan-sabira-hw3/sentiment_results_sync/ai-bubble-us-economy_1765755103.json\n",
      "\n",
      "Processing file: raw_articles/english/are-we-in-an-ai-bubble-we-asked-european-investors_1765755129.txt\n",
      "  [SUCCESS] Sentiment analyzed: NEUTRAL. Results uploaded to s3://aruzhan-sabira-hw3/sentiment_results_sync/are-we-in-an-ai-bubble-we-asked-european-investors_1765755129.json\n",
      "\n",
      "Processing file: raw_articles/english/c11d1f63-a085-419d-bc62-030911459304_1765755107.txt\n",
      "  [SUCCESS] Sentiment analyzed: NEUTRAL. Results uploaded to s3://aruzhan-sabira-hw3/sentiment_results_sync/c11d1f63-a085-419d-bc62-030911459304_1765755107.json\n",
      "\n",
      "Processing file: raw_articles/english/japan-media-ai-threat_1765755117.txt\n",
      "  [SUCCESS] Sentiment analyzed: NEUTRAL. Results uploaded to s3://aruzhan-sabira-hw3/sentiment_results_sync/japan-media-ai-threat_1765755117.json\n",
      "\n",
      "Processing file: raw_articles/english/kazakhstan-advances-ai-digital-ecosystem-developme_1765755136.txt\n",
      "  [SUCCESS] Sentiment analyzed: NEUTRAL. Results uploaded to s3://aruzhan-sabira-hw3/sentiment_results_sync/kazakhstan-advances-ai-digital-ecosystem-developme_1765755136.json\n",
      "\n",
      "Processing file: raw_articles/english/uzbekistan-to-lay-off-over-2000-government-employe_1765755133.txt\n",
      "  [SUCCESS] Sentiment analyzed: NEUTRAL. Results uploaded to s3://aruzhan-sabira-hw3/sentiment_results_sync/uzbekistan-to-lay-off-over-2000-government-employe_1765755133.json\n",
      "\n",
      "--- Listing files in translated_articles/ ---\n",
      "\n",
      "Processing file: translated_articles/1206507_1765755140.txt\n",
      "  [SUCCESS] Sentiment analyzed: NEUTRAL. Results uploaded to s3://aruzhan-sabira-hw3/sentiment_results_sync/1206507_1765755140.json\n",
      "\n",
      "Processing file: translated_articles/124362358.cms_1765755113.txt\n",
      "  [SUCCESS] Sentiment analyzed: NEUTRAL. Results uploaded to s3://aruzhan-sabira-hw3/sentiment_results_sync/124362358.cms_1765755113.json\n",
      "\n",
      "Processing file: translated_articles/blasen-bei-ki-werten-platzen-sie-bald-oder-geht-da_1765755100.txt\n",
      "  [SUCCESS] Sentiment analyzed: NEUTRAL. Results uploaded to s3://aruzhan-sabira-hw3/sentiment_results_sync/blasen-bei-ki-werten-platzen-sie-bald-oder-geht-da_1765755100.json\n",
      "\n",
      "Processing file: translated_articles/eksperty-vse-chasche-nazyvayut-bum-iskusstvennogo-_1765755110.txt\n",
      "  [SUCCESS] Sentiment analyzed: NEUTRAL. Results uploaded to s3://aruzhan-sabira-hw3/sentiment_results_sync/eksperty-vse-chasche-nazyvayut-bum-iskusstvennogo-_1765755110.json\n",
      "\n",
      "Processing file: translated_articles/resultados-da-oracle-sinalizam-bolha-de-ia-entenda_1765755120.txt\n",
      "  [SUCCESS] Sentiment analyzed: NEUTRAL. Results uploaded to s3://aruzhan-sabira-hw3/sentiment_results_sync/resultados-da-oracle-sinalizam-bolha-de-ia-entenda_1765755120.json\n",
      "\n",
      "Processing file: translated_articles/une-bulle-de-l-intelligence-artificielle_1765755126.txt\n",
      "  [SUCCESS] Sentiment analyzed: NEUTRAL. Results uploaded to s3://aruzhan-sabira-hw3/sentiment_results_sync/une-bulle-de-l-intelligence-artificielle_1765755126.json\n",
      "\n",
      "Synchronous sentiment analysis complete. Results are in the 'sentiment_results_sync/' folder.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(f\"Starting synchronous sentiment analysis in region {AWS_REGION}...\")\n",
    "\n",
    "    # Iterate over both input folders\n",
    "    for prefix in S3_INPUT_PREFIXES:\n",
    "        print(f\"\\n--- Listing files in {prefix} ---\")\n",
    "        \n",
    "        file_list_response = s3_client.list_objects_v2(\n",
    "            Bucket=S3_BUCKET_NAME, \n",
    "            Prefix=prefix\n",
    "        )\n",
    "        \n",
    "        if 'Contents' not in file_list_response:\n",
    "            print(\"No files found.\")\n",
    "            continue\n",
    "        \n",
    "        for obj in file_list_response['Contents']:\n",
    "            input_key = obj['Key']\n",
    "            \n",
    "            # Skip the folder itself\n",
    "            if input_key.endswith('/'):\n",
    "                continue\n",
    "            \n",
    "            process_s3_file(S3_BUCKET_NAME, input_key)\n",
    "            time.sleep(1) # Be polite to the API rate limits\n",
    "\n",
    "    print(\"\\nSynchronous sentiment analysis complete. Results are in the 'sentiment_results_sync/' folder.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
